{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the Project\n",
    "\n",
    "For this assignment, you can find the `smart cab` folder containing the necessary project files on the [Machine Learning projects GitHub](https://github.com/udacity/machine-learning), under the `projects` folder. You may download all of the files for projects we'll use in this Nanodegree program directly from this repo. Please make sure that you use the most recent version of project files when completing a project!\n",
    "\n",
    "This project contains two directories:\n",
    "\n",
    "- `/images/`: This folder contains various images of cars to be used in the graphical user interface. You will not need to modify or create any files in this directory.\n",
    "- `/smartcab/`: This folder contains the Python scripts that create the environment, graphical user interface, the simulation, and the agents. You will not need to modify or create any files in this directory except for `agent.py`.\n",
    "\n",
    "In `/smartcab/` are the following four files:\n",
    "- **Modify:**\n",
    "  - `agent.py`: This is the main Python file where you will be performing your work on the project.\n",
    "- **Do not modify:**\n",
    "  - `environment.py`: This Python file will create the **smartcab** environment.\n",
    "  - `planner.py`: This Python file creates a high-level planner for the agent to follow towards a set goal.\n",
    "  - `simulation.py`: This Python file creates the simulation and graphical user interface. \n",
    "\n",
    "### Environment\n",
    "The **smartcab** operates in an ideal, grid-like city (similar to New York City), with roads going in the North-South and East-West directions. Other vehicles will certainly be present on the road, but there will be no pedestrians to be concerned with. At each intersection there is a traffic light that either allows traffic in the North-South direction or the East-West direction. U.S. Right-of-Way rules apply: \n",
    "- On a green light, a left turn is permitted if there is no oncoming traffic making a right turn or coming straight through the intersection.\n",
    "-On a red light, a right turn is permitted if no oncoming traffic is approaching from your left through the intersection.\n",
    "\n",
    "### Inputs and Outputs\n",
    "The **smartcab** has only an egocentric view of the intersection it is at: It can determine the state of the traffic light for its direction of movement, and whether there is a vehicle at the intersection for each of the oncoming directions. For each action, the **smartcab** may either idle at the intersection, or drive to the next intersection to the left, right, or ahead of it. Finally, each trip has a time to reach the destination which decreases for each action taken (the passengers want to get there quickly).  If the allotted time becomes zero before reaching the destination, the trip has failed.\n",
    "\n",
    "### Rewards and Goal\n",
    "The **smartcab** receives a reward for each successfully completed trip, and also receives a smaller reward for each action it executes successfully that obeys traffic rules. The **smartcab** receives a small penalty for any incorrect action, and a larger penalty for any action that violates traffic rules or causes an accident with another vehicle. Based on the rewards and penalties the **smartcab** receives, the self-driving agent implementation should learn an optimal policy for driving on the city roads while obeying traffic rules, avoiding accidents, and reaching passengers? destinations in the allotted time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "### Project Report\n",
    "You will be required to submit a project report along with your modified agent code as part of your submission. As you complete the tasks below, include thorough, detailed answers to each question *provided in italics*.\n",
    "\n",
    "### Implement a Basic Driving Agent\n",
    "\n",
    "To begin, your only task is to get the **smartcab** to move around in the environment. At this point, you will not be concerned with any sort of optimal driving policy. Note that the driving agent is given the following information at each intersection:\n",
    "- The next waypoint location relative to its current location and heading.\n",
    "- The state of the traffic light at the intersection and the presence of oncoming vehicles from other directions.\n",
    "- The current time left from the allotted deadline.\n",
    "\n",
    "To complete this task, simply have your driving agent choose a random action from the set of possible actions (`None`, `'forward'`, `'left'`, `'right'`) at each intersection, disregarding the input information above. Set the simulation deadline enforcement, `enforce_deadline` to `False` and observe how it performs.\n",
    "\n",
    "***QUESTION:*** _Observe what you see with the agent's behavior as it takes random actions. Does the **smartcab** eventually make it to the destination? Are there any other interesting observations to note?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "The smartcab chooses randomly in actions and seems to perform a random walk in position as well as in rewards. The smartcab does make it to the destination after very many iterations. \n",
    "\n",
    "It is interesting to note, that the other agents seem to be moving around rather random as well. Furthermore, the reported state of the agent is always set to 'None'. Therefore you can see the state is not yet implemented/used in the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inform the Driving Agent\n",
    "\n",
    "Now that your driving agent is capable of moving around in the environment, your next task is to identify a set of states that are appropriate for modeling the **smartcab** and environment. The main source of state variables are the current inputs at the intersection, but not all may require representation. You may choose to explicitly define states, or use some combination of inputs as an implicit state. At each time step, process the inputs and update the agent's current state using the `self.state` variable. Continue with the simulation deadline enforcement `enforce_deadline` being set to `False`, and observe how your driving agent now reports the change in state as the simulation progresses.\n",
    "\n",
    "***QUESTION:*** _What states have you identified that are appropriate for modeling the **smartcab** and environment? Why do you believe each of these states to be appropriate for this problem?_\n",
    "\n",
    "***OPTIONAL:*** _How many states in total exist for the **smartcab** in this environment? Does this number seem reasonable given that the goal of Q-Learning is to learn and make informed decisions about each state? Why or why not?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "I believe the inputs as well as the self.next_waypoint values are important to determine the exact state the cab is in. Inputs are necessary since this determines whether a move is allowed by traffic rules or not. The next_waypoint is necessary to advise the cab what a good move would be, which is to say what direction would yield a reward, i.e. bring the cab closer to the end point. One could consider also using the deadline for the state, and how close one is to the destination. With a little work this could be used without exploding the possible state number (smart binning: closeness = near for distance < 4 points, etc, therefore binning into 2 bins). Then the cab could learn something like: If I now cross the road even if there is a red light I can still make it and get my reward. But for now I consider this too much, and rather a possibility for future add-ons. (This would still increase state-space by a factor 4)\n",
    "\n",
    "\n",
    "To answer the optional question let's take a look at: inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
    "next_waypoint: right.\n",
    "The total number of states is just: 2 x 2 x 2 x 2 x 3 (green/red, None/yes, None/yes, None/yes, forward/left/right)\n",
    "= 48 states in total. This seems to be a very reasonable number of states, that should be manageable to master for the Learning Agent.\n",
    "For every state there are 4 possible actions to be taken. Therefore there are 192 values for the utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a Q-Learning Driving Agent\n",
    "\n",
    "With your driving agent being capable of interpreting the input information and having a mapping of environmental states, your next task is to implement the Q-Learning algorithm for your driving agent to choose the *best* action at each time step, based on the Q-values for the current state and action. Each action taken by the **smartcab** will produce a reward which depends on the state of the environment. The Q-Learning driving agent will need to consider these rewards when updating the Q-values. Once implemented, set the simulation deadline enforcement `enforce_deadline` to `True`. Run the simulation and observe how the **smartcab** moves about the environment in each trial.\n",
    "\n",
    "The formulas for updating Q-values can be found in [this](https://classroom.udacity.com/nanodegrees/nd009/parts/0091345409/modules/e64f9a65-fdb5-4e60-81a9-72813beebb7e/lessons/5446820041/concepts/6348990570923) video.\n",
    "\n",
    "***QUESTION:*** _What changes do you notice in the agent's behavior when compared to the basic driving agent when random actions were always taken? Why is this behavior occurring?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "The agent very quickly learns to follow the next_waypoints. Therefore he quickly learns to reach the final destinations. Decisions are now rather independent from traffic light, therefore the agent basically learns to just follow the next_waypoints. Also, the agent rarely ever commits actions that will yield a penalty, after a few runs.\n",
    "\n",
    "Before, the agent was just choosing an action randomly, not learning anything and not ever reaching the final destination.\n",
    "\n",
    "The behaviour that is seen now occurs due to the memory effect that the utility has: Once in the same state as before, the agent will know that last time an action did not yield good results or that an action did lead to the wanted reward. Rewards and penalties lead to this effect, as a positive reward leads to a positive utility and a higher value of utility is preferred in the policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the Q-Learning Driving Agent\n",
    "\n",
    "Your final task for this project is to enhance your driving agent so that, after sufficient training, the **smartcab** is able to reach the destination within the allotted time safely and efficiently. Parameters in the Q-Learning algorithm, such as the learning rate (`alpha`), the discount factor (`gamma`) and the exploration rate (`epsilon`) all contribute to the driving agent?s ability to learn the best action for each state. To improve on the success of your **smartcab**:\n",
    "- Set the number of trials, `n_trials`, in the simulation to 100.\n",
    "- Run the simulation with the deadline enforcement `enforce_deadline` set to `True` (you will need to reduce the update delay `update_delay` and set the `display` to `False`).\n",
    "- Observe the driving agent?s learning and **smartcab?s** success rate, particularly during the later trials.\n",
    "- Adjust one or several of the above parameters and iterate this process.\n",
    "\n",
    "This task is complete once you have arrived at what you determine is the best combination of parameters required for your driving agent to learn successfully. \n",
    "\n",
    "***QUESTION:*** _Report the different values for the parameters tuned in your basic implementation of Q-Learning. For which set of parameters does the agent perform best? How well does the final driving agent perform?_\n",
    "\n",
    "***QUESTION:*** _Does your agent get close to finding an optimal policy, i.e. reach the destination in the minimum possible time, and not incur any penalties? How would you describe an optimal policy for this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "My initial parameters before were: alpha=0.1, gamma=0.1, epsilon=0.1. With these parameters the agent already quickly learned its way around and after the first run already reached every destination. I tried to make epsilon decay and start at a higher value, though that did not seem to change much. Therefore I would prefer to have a rather constant epsilon during training, and when you would actually want to use the trained smartcab, one should deactivate epsilon, as the optimal policy should be learned by then. Then I tried to make the agent learn what actions will result in penalties quicker. But I guess to learn this the agent has to randomly visit the consequences of all possible bad actions. In order to make it quicker, I started at a higher alpha of 0.5 and let it decay exponentially with alpha -= alpha/200. This seems to speed up the learning a bit. A gamma parameter of 0.2 also seems to increase the learning a bit.\n",
    "\n",
    "I therefore choose these parameters as my final parameters: alpha=0.5 (decays over time), gamma = 0.2, epsilon=0.1.\n",
    "\n",
    "This final driving agent reaches every destination. The first run with a deadline of 30 is reached with a deadline of 18 still left. Starting at about run 4 the agent seems to no longer receive any penalties except for when the action was taken randomly due to epsilon.\n",
    "\n",
    "Therefore I would argue, that this agent learns quickly (reaches destination in 1st run; learns to avoid penalties quickly) and brings passengers safe (learns quick toa void penalties) and reliably(always reaches destination in time) to their destination.\n",
    "\n",
    "\n",
    "There are things that are not done optimally yet. The agent right now basically learns to follow the next_waypoint and waits at every traffic light until it allows to travel to the next_waypoint. This is not efficient though. In this Manhatten street world, most often there are 2 optimal next_waypoints, not only one (only exception being when a straight line lies between destination and smartcab). Therefore at nearly all traffic light situations waiting is not the optimal action. But the cab waits anyway, as it does not know the final destination point but is only fed the next_waypoint. If the next_waypoint would allow for all optimal next_waypoints, or the cab was fed the final destination as well, it could learn this more optimal behaviour. I would argue, that adding the additional next_waypoint is the better solution, as the state-space stays at the same size and still allows for quick learning. Adding all the possible final destinations will make the state space bigger by a high factor (if I remember correctly 8 * 8 = 64), therefore making it very unlikely for the smartcab to visit all relevant states. A not yet learned final-destination will be a complete new state for the cab then, which is not really a desired situation.\n",
    "\n",
    "The description of the actual agent in combination with the point just above would be my optimal policy, that is not yet completely fulfilled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the Project\n",
    "\n",
    "### Evaluation\n",
    "Your project will be reviewed by a Udacity reviewer against the **<a href=\"https://review.udacity.com/#!/rubrics/106/view\" target=\"_blank\">Train a Smartcab to Drive project rubric</a>**. Be sure to review this rubric thoroughly and self-evaluate your project before submission. All criteria found in the rubric must be *meeting specifications* for you to pass.\n",
    "\n",
    "### Submission Files\n",
    "When you are ready to submit your project, collect the following files and compress them into a single archive for upload. Alternatively, you may supply the following files on your GitHub Repo in a folder named `smartcab` for ease of access:\n",
    " - The `agent.py` Python file with all code implemented as required in the instructed tasks.\n",
    " - A **PDF** project report with the name **report.pdf** which answers all of the questions related to the tasks completed. This file *must* be present for your project to be evaluated.\n",
    "\n",
    "Once you have collected these files and reviewed the project rubric, proceed to the project submission page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulator.run(): Trial 0\n",
      "Environment.reset(): Trial set up with start = (1, 6), destination = (4, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (4, 3)\n",
      "!!!! alpha = 0.4975\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.4950125\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.4925374375\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.490074750313\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.487624376561\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.485186254678\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.482760323405\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.480346521788\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.477944789179\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.475555065233\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.473177289907\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.470811403457\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.46845734644\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 1\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (5, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 4)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.466115059708\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.463784484409\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.461465561987\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.459158234177\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.456862443006\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.454578130791\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.452305240137\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.450043713937\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.447793495367\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.44555452789\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.443326755251\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.441110121474\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.438904570867\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.436710048013\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.434526497773\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.432353865284\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.430192095957\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.428041135478\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.4259009298\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.423771425151\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 2\n",
      "Environment.reset(): Trial set up with start = (8, 6), destination = (1, 4), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (1, 4)\n",
      "!!!! alpha = 0.421652568025\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.419544305185\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.417446583659\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.415359350741\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.413282553987\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.411216141217\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.409160060511\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.407114260209\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.405078688908\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.403053295463\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.401038028986\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.399032838841\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.397037674647\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.395052486274\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.393077223842\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.391111837723\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.389156278534\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.387210497142\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.385274444656\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.383348072433\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.38143133207\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.37952417541\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.377626554533\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.37573842176\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.373859729652\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.371990431003\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.370130478848\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.368279826454\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.366438427322\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.364606235185\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.362783204009\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.360969287989\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.359164441549\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.357368619342\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.355581776245\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.353803867364\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.352034848027\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.350274673787\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.348523300418\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.346780683916\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 3\n",
      "Environment.reset(): Trial set up with start = (6, 3), destination = (2, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (2, 5)\n",
      "!!!! alpha = 0.345046780496\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.343321546594\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.341604938861\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.339896914166\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.338197429595\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.336506442448\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.334823910235\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.333149790684\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.331484041731\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.329826621522\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.328177488414\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.326536600972\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.324903917967\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 4\n",
      "Environment.reset(): Trial set up with start = (4, 2), destination = (2, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 4)\n",
      "!!!! alpha = 0.323279398378\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.321663001386\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.320054686379\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.318454412947\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.316862140882\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 5\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (1, 2), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (1, 2)\n",
      "!!!! alpha = 0.315277830178\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.313701441027\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.312132933822\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.310572269153\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.309019407807\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.307474310768\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.305936939214\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.304407254518\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.302885218245\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.301370792154\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 6\n",
      "Environment.reset(): Trial set up with start = (4, 2), destination = (6, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.299863938193\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.298364618502\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.29687279541\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.295388431433\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 7\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (7, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!!! alpha = 0.293911489276\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.292441931829\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.29097972217\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.289524823559\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.288077199442\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.286636813444\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.285203629377\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.28377761123\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.282358723174\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.280946929558\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.27954219491\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.278144483936\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.276753761516\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.275369992709\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.273993142745\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.272623177031\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.271260061146\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.26990376084\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.268554242036\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.267211470826\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.265875413472\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 8\n",
      "Environment.reset(): Trial set up with start = (8, 4), destination = (4, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "!!!! alpha = 0.264546036405\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.263223306223\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.261907189691\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.260597653743\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.259294665474\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.257998192147\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 9\n",
      "Environment.reset(): Trial set up with start = (7, 4), destination = (1, 4), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (1, 4)\n",
      "!!!! alpha = 0.256708201186\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.25542466018\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.254147536879\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.252876799195\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.251612415199\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.250354353123\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.249102581357\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.247857068451\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.246617783108\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.245384694193\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.244157770722\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 10\n",
      "Environment.reset(): Trial set up with start = (8, 6), destination = (6, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!!! alpha = 0.242936981868\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.241722296959\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.240513685474\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.239311117047\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.238114561461\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.236923988654\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.235739368711\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.234560671867\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.233387868508\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.232220929165\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.23105982452\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.229904525397\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.22875500277\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.227611227756\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.226473171617\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.225340805759\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 11\n",
      "Environment.reset(): Trial set up with start = (2, 6), destination = (7, 2), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (7, 2)\n",
      "!!!! alpha = 0.22421410173\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.223093031222\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.221977566066\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.220867678235\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.219763339844\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.218664523145\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.217571200529\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.216483344527\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.215400927804\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.214323923165\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.213252303549\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.212186042031\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.211125111821\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.210069486262\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 12\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (4, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "!!!! alpha = 0.209019138831\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.207974043137\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.206934172921\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.205899502056\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.204870004546\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.203845654523\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.202826426251\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.20181229412\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.200803232649\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 13\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (6, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (6, 3)\n",
      "!!!! alpha = 0.199799216486\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.198800220403\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.197806219301\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.196817188205\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.195833102264\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.194853936752\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.193879667069\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.192910268733\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.19194571739\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.190985988803\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.190031058859\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.189080903564\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.188135499047\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 14\n",
      "Environment.reset(): Trial set up with start = (8, 2), destination = (3, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (3, 3)\n",
      "!!!! alpha = 0.187194821551\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.186258847444\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.185327553206\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.18440091544\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.183478910863\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.182561516309\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.181648708727\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.180740465184\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.179836762858\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.178937579043\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.178042891148\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.177152676692\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.176266913309\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.175385578742\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 15\n",
      "Environment.reset(): Trial set up with start = (2, 3), destination = (6, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!!! alpha = 0.174508650849\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.173636107594\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.172767927056\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.171904087421\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.171044566984\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.170189344149\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.169338397428\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.168491705441\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.167649246914\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.16681100068\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.165976945676\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.165147060948\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.164321325643\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.163499719015\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.16268222042\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.161868809318\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.161059465271\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.160254167945\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.159452897105\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.158655632619\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 16\n",
      "Environment.reset(): Trial set up with start = (2, 5), destination = (6, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!!! alpha = 0.157862354456\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.157073042684\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.156287677471\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.155506239083\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.154728707888\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.153955064348\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.153185289027\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.152419362582\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.151657265769\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.15089897944\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.150144484543\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.14939376212\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.148646793309\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.147903559343\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.147164041546\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 17\n",
      "Environment.reset(): Trial set up with start = (2, 5), destination = (2, 1), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 1)\n",
      "!!!! alpha = 0.146428221338\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.145696080232\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.14496759983\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.144242761831\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 18\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (7, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 4)\n",
      "!!!! alpha = 0.143521548022\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.142803940282\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.142089920581\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.141379470978\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.140672573623\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.139969210755\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.139269364701\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.138573017877\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.137880152788\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.137190752024\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.136504798264\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.135822274273\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.135143162901\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.134467447087\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.133795109851\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.133126134302\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 19\n",
      "Environment.reset(): Trial set up with start = (4, 4), destination = (7, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!!! alpha = 0.132460503631\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.131798201112\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.131139210107\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.130483514056\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.129831096486\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.129181941004\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.128536031299\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.127893351142\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.127253884386\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.126617614964\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 20\n",
      "Environment.reset(): Trial set up with start = (6, 4), destination = (4, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 1)\n",
      "!!!! alpha = 0.12598452689\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.125354604255\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.124727831234\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.124104192078\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.123483671117\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.122866252762\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.122251921498\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.12164066189\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.121032458581\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.120427296288\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 21\n",
      "Environment.reset(): Trial set up with start = (6, 6), destination = (4, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 4)\n",
      "!!!! alpha = 0.119825159807\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.119226034008\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.118629903838\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.118036754318\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.117446570547\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.116859337694\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.116275041006\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.115693665801\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.115115197472\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.114539621484\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.113966923377\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 22\n",
      "Environment.reset(): Trial set up with start = (3, 6), destination = (1, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (1, 2)\n",
      "!!!! alpha = 0.11339708876\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.112830103316\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.1122659528\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.111704623036\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.11114609992\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.110590369421\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.110037417574\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.109487230486\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.108939794333\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.108395095362\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.107853119885\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.107313854285\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.106777285014\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.106243398589\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.105712181596\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.105183620688\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.104657702585\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.104134414072\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.103613742001\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.103095673291\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.102580194925\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.10206729395\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.10155695748\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.101049172693\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.10054392683\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.100041207195\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0995410011595\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0990432961537\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 23\n",
      "Environment.reset(): Trial set up with start = (1, 4), destination = (6, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0985480796729\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0980553392746\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0975650625782\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0970772372653\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.096591851079\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0961088918236\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0956283473645\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0951502056276\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0946744545995\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0942010823265\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0937300769149\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0932614265303\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0927951193976\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0923311438007\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0918694880817\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 24\n",
      "Environment.reset(): Trial set up with start = (5, 3), destination = (8, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (8, 1)\n",
      "!!!! alpha = 0.0914101406412\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.090953089938\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0904983244883\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0900458328659\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0895956037016\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0891476256831\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0887018875547\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0882583781169\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 25\n",
      "Environment.reset(): Trial set up with start = (4, 3), destination = (8, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (8, 2)\n",
      "!!!! alpha = 0.0878170862263\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0873780007952\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0869411107912\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0865064052372\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.086073873211\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.085643503845\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0852152863258\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0847892098941\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0843652638447\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 26\n",
      "Environment.reset(): Trial set up with start = (2, 4), destination = (5, 6), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (5, 6)\n",
      "!!!! alpha = 0.0839434375254\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0835237203378\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0831061017361\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0826905712274\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 27\n",
      "Environment.reset(): Trial set up with start = (7, 1), destination = (4, 6), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (4, 6)\n",
      "!!!! alpha = 0.0822771183713\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0818657327795\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0814564041156\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.081049122095\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0806438764845\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0802406571021\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0798394538166\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0794402565475\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0790430552647\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0786478399884\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0782546007885\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0778633277845\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0774740111456\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.0770866410899\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0767012078844\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 28\n",
      "Environment.reset(): Trial set up with start = (5, 5), destination = (7, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!!! alpha = 0.076317701845\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0759361133358\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0755564327691\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0751786506053\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0748027573522\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0744287435655\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 29\n",
      "Environment.reset(): Trial set up with start = (8, 2), destination = (3, 5), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (3, 5)\n",
      "!!!! alpha = 0.0740565998477\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0736863168484\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0733178852642\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0729512958379\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0725865393587\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0722236066619\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0718624886286\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.0715031761854\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0711456603045\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.070789932003\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.070435982343\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0700838024312\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0697333834191\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.069384716502\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 30\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (5, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (5, 4)\n",
      "!!!! alpha = 0.0690377929195\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0686926039549\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0683491409351\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0680073952304\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.0676673582543\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.067329021463\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0669923763557\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0666574144739\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0663241274015\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0659925067645\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0656625442307\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 31\n",
      "Environment.reset(): Trial set up with start = (2, 6), destination = (7, 1), deadline = 50\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "!!!! alpha = 0.0653342315096\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.065007560352\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0646825225503\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0643591099375\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0640373143878\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 46, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0637171278159\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0633985421768\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0630815494659\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0627661417186\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.06245231101\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.0621400494549\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0618293492077\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0615202024616\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0612126014493\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0609065384421\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0606020057499\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0602989957211\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 32\n",
      "Environment.reset(): Trial set up with start = (6, 5), destination = (4, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 2)\n",
      "!!!! alpha = 0.0599975007425\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0596975132388\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0593990256726\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.0591020305442\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0588065203915\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0585124877896\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0582199253506\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 33\n",
      "Environment.reset(): Trial set up with start = (7, 4), destination = (2, 6), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (2, 6)\n",
      "!!!! alpha = 0.0579288257239\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0576391815952\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0573509856873\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0570642307588\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.056778909605\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.056495015057\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0562125399817\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0559314772818\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0556518198954\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0553735607959\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0550966929919\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.054821209527\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0545471034794\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.054274367962\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0540029961221\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0537329811415\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0534643162358\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0531969946546\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0529310096814\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.052666354633\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0524030228598\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0521410077455\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0518803027068\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0516209011932\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0513627966873\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0511059827038\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0508504527903\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0505962005264\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0503432195237\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0500915034261\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.049841045909\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0495918406794\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.049343881476\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0490971620687\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0488516762583\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 34\n",
      "Environment.reset(): Trial set up with start = (4, 6), destination = (6, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!!! alpha = 0.048607417877\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0483643807876\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0481225588837\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0478819460893\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0476425363588\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.047404323677\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0471673020587\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0469314655484\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0466968082206\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0464633241795\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0462310075586\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0459998525208\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0457698532582\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0455410039919\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.045313298972\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0450867324771\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0448612988147\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0446369923207\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0444138073591\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0441917383223\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 35\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (5, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (5, 2)\n",
      "!!!! alpha = 0.0439707796306\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0437509257325\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0435321711038\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0433145102483\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0430979376971\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0428824480086\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0426680357685\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0424546955897\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0422424221118\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0420312100012\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0418210539512\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0416119486814\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.041403888938\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0411968694933\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0409908851459\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 36\n",
      "Environment.reset(): Trial set up with start = (1, 2), destination = (3, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (3, 5)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0407859307201\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.0405820010665\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0403790910612\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0401771956059\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0399763096279\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0397764280797\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 37\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (7, 3), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!!! alpha = 0.0395775459393\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0393796582096\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0391827599186\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.038986846119\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0387919118884\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.038597952329\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0384049625673\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0382129377545\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0380218730657\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 38\n",
      "Environment.reset(): Trial set up with start = (7, 2), destination = (1, 4), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (1, 4)\n",
      "!!!! alpha = 0.0378317637004\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0376426048819\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0374543918575\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0372671198982\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0370807842987\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0368953803772\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0367109034753\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0365273489579\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0363447122131\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0361629886521\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0359821737088\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0358022628403\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.0356232515261\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0354451352684\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0352679095921\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0350915700441\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0349161121939\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0347415316329\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0345678239748\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0343949848549\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0342230099306\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.034051894881\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0338816354066\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0337122272295\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0335436660934\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0333759477629\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0332090680241\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.033043022684\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0328778075706\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0327134185327\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0325498514401\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0323871021829\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0322251666719\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 39\n",
      "Environment.reset(): Trial set up with start = (2, 3), destination = (6, 1), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 1)\n",
      "!!!! alpha = 0.0320640408386\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0319037206344\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0317442020312\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.0315854810211\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.031427553616\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 40\n",
      "Environment.reset(): Trial set up with start = (7, 1), destination = (5, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 3)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0312704158479\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0311140637686\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0309584934498\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0308037009825\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0306496824776\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0304964340652\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0303439518949\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0301922321354\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0300412709748\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 41\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (8, 5), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "!!!! alpha = 0.0298910646199\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0297416092968\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0295929012503\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0294449367441\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0292977120603\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0291512235\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0290054673825\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.0288604400456\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0287161378454\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0285725571562\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0284296943704\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0282875458985\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.028146108169\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0280053776282\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0278653507401\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0277260239864\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0275873938664\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0274494568971\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0273122096126\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0271756485645\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0270397703217\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 42\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (2, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 5)\n",
      "!!!! alpha = 0.0269045714701\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0267700486128\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0266361983697\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0265030173778\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.026370502291\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0262386497795\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0261074565306\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.025976919248\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0258470346517\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0257177994785\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0255892104811\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0254612644287\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0253339581065\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.025207288316\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0250812518744\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.024955845615\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.024831066387\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.024706911055\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 43\n",
      "Environment.reset(): Trial set up with start = (7, 1), destination = (1, 1), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (1, 1)\n",
      "!!!! alpha = 0.0245833764997\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0244604596172\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0243381573192\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0242164665326\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0240953841999\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0239749072789\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0238550327425\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0237357575788\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0236170787909\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0234989933969\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.02338149843\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0232645909378\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0231482679831\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0230325266432\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.02291736401\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0228027771899\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.022688763304\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0225753194875\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.02246244289\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0223501306756\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0222383800222\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 44\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (7, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 6)\n",
      "!!!! alpha = 0.0221271881221\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0220165521815\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0219064694206\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0217969370735\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0216879523881\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0215795126262\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 45\n",
      "Environment.reset(): Trial set up with start = (7, 2), destination = (2, 4), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (2, 4)\n",
      "!!!! alpha = 0.021471615063\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0213642569877\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0212574357028\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0211511485243\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0210453927816\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0209401658177\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0208354649886\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0207312876637\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 46\n",
      "Environment.reset(): Trial set up with start = (4, 3), destination = (8, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "!!!! alpha = 0.0206276312254\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0205244930693\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0204218706039\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0203197612509\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0202181624446\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0201170716324\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0200164862743\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0199164038429\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0198168218237\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0197177377146\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.019619149026\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0195210532808\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0194234480144\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 47\n",
      "Environment.reset(): Trial set up with start = (7, 3), destination = (2, 1), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (2, 1)\n",
      "!!!! alpha = 0.0193263307744\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0192296991205\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0191335506249\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0190378828718\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0189426934574\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0188479799901\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0187537400902\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0186599713897\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0185666715328\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0184738381751\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0183814689842\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0182895616393\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 48\n",
      "Environment.reset(): Trial set up with start = (7, 3), destination = (8, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (8, 6)\n",
      "!!!! alpha = 0.0181981138311\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.018107123262\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0180165876457\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0179265047074\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0178368721839\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.017747687823\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0176589493839\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0175706546369\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 49\n",
      "Environment.reset(): Trial set up with start = (1, 2), destination = (6, 4), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (6, 4)\n",
      "!!!! alpha = 0.0174828013638\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0173953873569\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0173084104201\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.017221868368\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0171357590262\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0170500802311\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0169648298299\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0168800056808\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0167956056524\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0167116276241\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.016628069486\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0165449291386\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0164622044929\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0163798934704\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.016297994003\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 50\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (2, 1), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (2, 1)\n",
      "!!!! alpha = 0.016216504033\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0161354215129\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0160547444053\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0159744706833\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0158945983299\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0158151253382\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0157360497115\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.015657369463\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0155790826156\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0155011872026\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0154236812666\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0153465628602\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0152698300459\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0151934808957\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0151175134912\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0150419259238\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0149667162941\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0148918827127\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0148174232991\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0147433361826\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 51\n",
      "Environment.reset(): Trial set up with start = (6, 2), destination = (5, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 5)\n",
      "!!!! alpha = 0.0146696195017\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0145962714042\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0145232900472\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 52\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (1, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (1, 3)\n",
      "!!!! alpha = 0.0144506735969\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0143784202289\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0143065281278\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0142349954872\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0141638205097\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.0140930014072\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 53\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (4, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 3)\n",
      "!!!! alpha = 0.0140225364001\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.0139524237181\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0138826615995\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0138132482916\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0137441820501\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0136754611398\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0136070838341\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.013539048415\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0134713531729\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.013403996407\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 54\n",
      "Environment.reset(): Trial set up with start = (6, 4), destination = (1, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (1, 2)\n",
      "!!!! alpha = 0.013336976425\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0132702915429\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0132039400852\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0131379203847\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0130722307828\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0130068696289\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0129418352808\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0128771261043\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 55\n",
      "Environment.reset(): Trial set up with start = (6, 4), destination = (3, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (3, 2)\n",
      "!!!! alpha = 0.0128127404738\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0127486767715\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0126849333876\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0126215087207\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0125584011771\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 56\n",
      "Environment.reset(): Trial set up with start = (1, 1), destination = (7, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (7, 2)\n",
      "!!!! alpha = 0.0124956091712\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0124331311253\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0123709654697\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0123091106423\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0122475650891\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0121863272637\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0121253956274\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0120647686492\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 57\n",
      "Environment.reset(): Trial set up with start = (6, 5), destination = (8, 1), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (8, 1)\n",
      "!!!! alpha = 0.012004444806\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.011944422582\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.011884700469\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0118252769667\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0117661505819\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.011707319829\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0116487832298\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0115905393137\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0115325866171\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.011474923684\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 58\n",
      "Environment.reset(): Trial set up with start = (7, 2), destination = (3, 4), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (3, 4)\n",
      "!!!! alpha = 0.0114175490656\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0113604613203\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0113036590137\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0112471407186\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.011190905015\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0111349504899\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0110792757375\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0110238793588\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.010968759962\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0109139161622\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0108593465814\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0108050498485\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0107510245992\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0106972694762\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0106437831288\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0105905642132\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 59\n",
      "Environment.reset(): Trial set up with start = (3, 5), destination = (8, 1), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (8, 1)\n",
      "!!!! alpha = 0.0105376113921\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0104849233352\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0104324987185\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0103803362249\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0103284345438\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0102767923711\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0102254084092\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0101742813672\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0101234099603\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0100727929105\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.010022428946\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00997231680124\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00992245521723\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00987284294115\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00982347872644\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00977436133281\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 60\n",
      "Environment.reset(): Trial set up with start = (3, 4), destination = (1, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (1, 1)\n",
      "!!!! alpha = 0.00972548952615\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00967686207851\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00962847776812\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00958033537928\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00953243370239\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00948477153387\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0094373476762\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00939016093782\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00934321013313\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00929649408247\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00925001161206\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.009203761554\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 61\n",
      "Environment.reset(): Trial set up with start = (5, 5), destination = (7, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00915774274623\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00911195403249\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00906639426233\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00902106229102\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 62\n",
      "Environment.reset(): Trial set up with start = (6, 3), destination = (4, 1), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 1)\n",
      "!!!! alpha = 0.00897595697957\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00893107719467\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00888642180869\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 63\n",
      "Environment.reset(): Trial set up with start = (4, 5), destination = (7, 3), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!!! alpha = 0.00884198969965\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00879777975115\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0087537908524\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00871002189813\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00866647178864\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0086231394297\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00858002373255\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 64\n",
      "Environment.reset(): Trial set up with start = (6, 4), destination = (1, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (1, 3)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00853712361389\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00849443799582\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00845196580584\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00840970597681\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00836765744693\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00832581915969\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00828419006389\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00824276911358\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00820155526801\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00816054749167\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00811974475421\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00807914603044\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00803875030029\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00799855654878\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00795856376604\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = left, reward = -1.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00791877094721\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.00787917709247\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00783978120701\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00780058230098\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00776157938947\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00772277149252\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00768415763506\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00764573684689\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00760750816265\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00756947062184\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00753162326873\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00749396515239\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00745649532662\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00741921284999\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00738211678574\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00734520620181\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 65\n",
      "Environment.reset(): Trial set up with start = (7, 2), destination = (7, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 6)\n",
      "!!!! alpha = 0.0073084801708\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00727193776995\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0072355780811\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 66\n",
      "Environment.reset(): Trial set up with start = (5, 3), destination = (2, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 1)\n",
      "!!!! alpha = 0.00719940019069\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00716340318974\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00712758617379\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00709194824292\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00705648850171\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0070212060592\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0069861000289\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00695116952876\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00691641368112\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00688183161271\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.00684742245465\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00681318534237\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00677911941566\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00674522381858\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00671149769949\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00667794021099\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 67\n",
      "Environment.reset(): Trial set up with start = (4, 3), destination = (1, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (1, 5)\n",
      "!!!! alpha = 0.00664455050994\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00661132775739\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0065782711186\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00654537976301\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00651265286419\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00648008959987\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00644768915187\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00641545070611\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00638337345258\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00635145658532\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 68\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (7, 3), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00631969930239\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00628810080588\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00625666030185\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00622537700034\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00619425011534\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00616327886476\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00613246247044\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00610180015809\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0060712911573\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 69\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (6, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!!! alpha = 0.00604093470151\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.006010730028\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00598067637786\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00595077299597\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00592101913099\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00589141403534\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00586195696516\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 70\n",
      "Environment.reset(): Trial set up with start = (2, 3), destination = (5, 6), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (5, 6)\n",
      "!!!! alpha = 0.00583264718034\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00580348394444\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00577446652471\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00574559419209\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.00571686622113\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00568828189002\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00565984048057\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00563154127817\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00560338357178\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 71\n",
      "Environment.reset(): Trial set up with start = (8, 4), destination = (6, 2), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "!!!! alpha = 0.00557536665392\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00554748982065\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00551975237155\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.00549215360969\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00546469284164\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00543736937743\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00541018253055\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00538313161789\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0053562159598\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00532943488\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 72\n",
      "Environment.reset(): Trial set up with start = (3, 6), destination = (6, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "!!!! alpha = 0.0053027877056\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00527627376708\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00524989239824\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00522364293625\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00519752472157\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00517153709796\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00514567941247\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 73\n",
      "Environment.reset(): Trial set up with start = (7, 6), destination = (2, 3), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (2, 3)\n",
      "!!!! alpha = 0.00511995101541\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00509435126033\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00506887950403\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00504353510651\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00501831743098\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00499322584382\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0049682597146\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00494341841603\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00491870132395\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00489410781733\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00486963727824\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 74\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (2, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 1)\n",
      "!!!! alpha = 0.00484528909185\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00482106264639\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00479695733316\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0047729725465\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00474910768376\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00472536214534\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.00470173533462\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00467822665794\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00465483552465\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00463156134703\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0046084035403\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00458536152259\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00456243471498\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00453962254141\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0045169244287\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00449433980656\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 75\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (8, 6), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (8, 6)\n",
      "!!!! alpha = 0.00447186810752\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00444950876699\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00442726122315\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00440512491704\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00438309929245\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00436118379599\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00433937787701\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00431768098762\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00429609258268\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00427461211977\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 76\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (5, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 4)\n",
      "!!!! alpha = 0.00425323905917\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00423197286388\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00421081299956\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00418975893456\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00416881013989\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00414796608919\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00412722625874\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00410659012745\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00408605717681\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00406562689093\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00404529875647\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00402507226269\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00400494690138\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00398492216687\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00396499755603\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 77\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (7, 1), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00394517256825\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00392544670541\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00390581947189\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00388629037453\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.00386685892265\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00384752462804\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0038282870049\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 78\n",
      "Environment.reset(): Trial set up with start = (2, 5), destination = (6, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (6, 4)\n",
      "!!!! alpha = 0.00380914556988\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00379009984203\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00377114934282\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0037522935961\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00373353212812\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00371486446748\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00369629014514\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00367780869442\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00365941965095\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00364112255269\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "!!!! alpha = 0.00362291693993\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00360480235523\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00358677834345\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 79\n",
      "Environment.reset(): Trial set up with start = (6, 1), destination = (2, 1), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 1)\n",
      "!!!! alpha = 0.00356884445174\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00355100022948\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00353324522833\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00351557900219\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00349800110718\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00348051110164\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00346310854613\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0034457930034\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00342856403838\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00341142121819\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 80\n",
      "Environment.reset(): Trial set up with start = (3, 3), destination = (2, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 6)\n",
      "!!!! alpha = 0.0033943641121\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00337739229154\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00336050533008\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00334370280343\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00332698428942\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00331034936797\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00329379762113\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 81\n",
      "Environment.reset(): Trial set up with start = (1, 1), destination = (7, 4), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (7, 4)\n",
      "!!!! alpha = 0.00327732863302\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00326094198986\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00324463727991\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00322841409351\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00321227202304\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00319621066293\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00318022960961\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00316432846156\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00314850681926\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00313276428516\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 82\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (6, 5), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "!!!! alpha = 0.00311710046373\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00310151496142\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00308600738661\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00307057734968\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00305522446293\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00303994834061\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00302474859891\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00300962485591\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00299457673164\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00297960384798\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 83\n",
      "Environment.reset(): Trial set up with start = (7, 6), destination = (2, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (2, 5)\n",
      "!!!! alpha = 0.00296470582874\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00294988229959\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0029351328881\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00292045722365\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00290585493754\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00289132566285\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00287686903453\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00286248468936\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00284817226592\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00283393140459\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00281976174756\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00280566293882\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00279163462413\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 84\n",
      "Environment.reset(): Trial set up with start = (3, 6), destination = (1, 1), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (1, 1)\n",
      "!!!! alpha = 0.00277767645101\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00276378806876\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00274996912841\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00273621928277\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00272253818636\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00270892549542\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00269538086795\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00268190396361\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00266849444379\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00265515197157\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.00264187621171\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00262866683065\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 85\n",
      "Environment.reset(): Trial set up with start = (5, 2), destination = (2, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 4)\n",
      "!!!! alpha = 0.0026155234965\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00260244587902\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00258943364962\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00257648648137\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00256360404897\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00255078602872\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00253803209858\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00252534193809\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0025127152284\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00250015165225\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00248765089399\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00247521263952\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 86\n",
      "Environment.reset(): Trial set up with start = (5, 4), destination = (2, 6), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 6)\n",
      "!!!! alpha = 0.00246283657632\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00245052239344\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.00243826978148\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00242607843257\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00241394804041\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0024018783002\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 87\n",
      "Environment.reset(): Trial set up with start = (1, 1), destination = (7, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (7, 2)\n",
      "!!!! alpha = 0.0023898689087\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00237791956416\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00236602996634\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00235419981651\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00234242881742\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00233071667334\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00231906308997\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00230746777452\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 88\n",
      "Environment.reset(): Trial set up with start = (1, 4), destination = (7, 2), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (7, 2)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00229593043565\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "!!!! alpha = 0.00228445078347\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00227302852955\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 89\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (7, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 6)\n",
      "!!!! alpha = 0.0022616633869\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00225035506997\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00223910329462\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00222790777815\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00221676823926\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00220568439806\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00219465597607\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00218368269619\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00217276428271\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0021619004613\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 90\n",
      "Environment.reset(): Trial set up with start = (2, 3), destination = (5, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (5, 1)\n",
      "!!!! alpha = 0.00215109095899\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00214033550419\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00212963382667\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00211898565754\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00210839072925\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00209784877561\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00208735953173\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00207692273407\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.0020665381204\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.0020562054298\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00204592440265\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00203569478063\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00202551630673\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0020153887252\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00200531178157\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 91\n",
      "Environment.reset(): Trial set up with start = (8, 1), destination = (6, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "!!!! alpha = 0.00199528522266\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00198530879655\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00197538225257\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.0019655053413\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.0019556778146\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00194589942553\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0019361699284\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00192648907876\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00191685663336\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00190727235019\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00189773598844\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0018882473085\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 92\n",
      "Environment.reset(): Trial set up with start = (5, 1), destination = (4, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 4)\n",
      "!!!! alpha = 0.00187880607196\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.0018694120416\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00186006498139\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00185076465648\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0018415108332\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00183230327904\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00182314176264\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00181402605383\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00180495592356\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 93\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (6, 4), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 4)\n",
      "!!!! alpha = 0.00179593114394\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00178695148822\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00177801673078\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00176912664713\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00176028101389\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00175147960882\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00174272221078\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00173400859972\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00172533855672\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00171671186394\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00170812830462\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 94\n",
      "Environment.reset(): Trial set up with start = (6, 2), destination = (1, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (1, 2)\n",
      "!!!! alpha = 0.0016995876631\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00169108972478\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00168263427616\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00167422110478\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00166584999925\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00165752074926\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 95\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (1, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (1, 6)\n",
      "!!!! alpha = 0.00164923314551\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00164098697978\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00163278204488\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00162461813466\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00161649504399\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00160841256877\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00160037050592\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00159236865339\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00158440681013\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00157648477608\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0015686023522\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00156075934043\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00155295554373\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00154519076601\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00153746481218\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00152977748812\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "!!!! alpha = 0.00152212860068\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 96\n",
      "Environment.reset(): Trial set up with start = (7, 5), destination = (3, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (3, 3)\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00151451795768\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00150694536789\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00149941064105\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00149191358785\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00148445401991\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00147703174981\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00146964659106\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.0014622983581\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00145498686631\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00144771193198\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00144047337232\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00143327100546\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00142610465043\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00141897412718\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00141187925654\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00140481986026\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "!!!! alpha = 0.00139779576096\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00139080678215\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00138385274824\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.0013769334845\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 97\n",
      "Environment.reset(): Trial set up with start = (1, 6), destination = (2, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 2)\n",
      "!!!! alpha = 0.00137004881708\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00136319857299\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00135638258013\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00134960066723\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00134285266389\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00133613840057\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00132945770857\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 98\n",
      "Environment.reset(): Trial set up with start = (7, 1), destination = (4, 5), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "!!!! alpha = 0.00132281042003\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00131619636793\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00130961538609\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00130306730916\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00129655197261\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00129006921275\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00128361886669\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00127720077235\n",
      "next_waypoint: left\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00127081476849\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "!!!! alpha = 0.00126446069465\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00125813839117\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "!!!! alpha = 0.00125184769922\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00124558846072\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!!! alpha = 0.00123936051842\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00123316371583\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "Simulator.run(): Trial 99\n",
      "Environment.reset(): Trial set up with start = (7, 4), destination = (2, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (2, 3)\n",
      "!!!! alpha = 0.00122699789725\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "!!!! alpha = 0.00122086290776\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00121475859322\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "!!!! alpha = 0.00120868480026\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00120264137626\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00119662816937\n",
      "next_waypoint: forward\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "!!! The following action is taken randomly !!!\n",
      "!!!! alpha = 0.00119064502853\n",
      "next_waypoint: right\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "Environment.act(): Primary agent has reached destination!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from smartcab.environment import Agent, Environment\n",
    "from smartcab.planner import RoutePlanner\n",
    "from smartcab.simulator import Simulator\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "class Utility():\n",
    "    def __init__(self, valid_actions, valid_inputs, alpha=0.5, gamma=0.2, epsilon=0.1):\n",
    "        self.Q_values = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.valid_actions = valid_actions\n",
    "        stateActionSpace = self.init_stateActionSpace(valid_actions, valid_inputs)\n",
    "        for state_and_action_pair in stateActionSpace:\n",
    "            self.Q_values[state_and_action_pair] = 0\n",
    "    \n",
    "    def update(self, old_state, action, reward, new_state):\n",
    "        #Q(s,a) = (1-/alpha)Q(s,a) + /alpha ( R(s) + \n",
    "        #sum_over_all_possible_next_states_s' /gamma max(Q(s',a') , with regard of a'))\n",
    "        oldStateKey = self.createStateActionKey(old_state, action)\n",
    "        Q = self.Q_values[oldStateKey]\n",
    "        Q_max = 0\n",
    "        for action in self.valid_actions:\n",
    "            newStateKey = self.createStateActionKey(new_state, action)\n",
    "            Q_candidate = self.Q_values[newStateKey]\n",
    "            if Q_candidate > Q_max:\n",
    "                Q_max = Q_candidate\n",
    "            \n",
    "        Q = (1-self.alpha)*Q + self.alpha*(reward + self.gamma*Q_max)\n",
    "        \n",
    "        self.alpha -= self.alpha/200\n",
    "        print \"!!!! alpha = {}\".format(self.alpha)\n",
    "        self.Q_values[oldStateKey] = Q\n",
    "    \n",
    "    def policy(self, state):\n",
    "        randomNumber = random.random()\n",
    "        if randomNumber > (1-self.epsilon):\n",
    "            print \"!!! The following action is taken randomly !!!\"\n",
    "            return random.choice(self.valid_actions)\n",
    "        else:\n",
    "            Q_max = 0\n",
    "            best_action = []\n",
    "            for action in self.valid_actions:\n",
    "                stateActionKey = self.createStateActionKey(state, action)\n",
    "                Q = self.Q_values[stateActionKey]\n",
    "                if Q > Q_max:\n",
    "                    Q_max = Q\n",
    "                    best_action = [action]\n",
    "                if Q == Q_max:\n",
    "                    best_action += [action]\n",
    "                    \n",
    "            if len(best_action)== 1:\n",
    "                return best_action[0]\n",
    "            else:\n",
    "                return random.choice(best_action)\n",
    "    \n",
    "    def init_stateActionSpace(self, valid_actions, valid_inputs):\n",
    "        possible_next_waypoints = valid_actions[1:]\n",
    "        stateActionSpace = []\n",
    "        state = {}\n",
    "        for light in ['red','green']:\n",
    "            for left in valid_inputs['left']:\n",
    "                for right in valid_inputs['right']:\n",
    "                    for oncoming in valid_inputs['oncoming']:\n",
    "                        for next_waypoint in possible_next_waypoints:\n",
    "                            for action in valid_actions:\n",
    "                                state = {'light': light, 'next_waypoint': next_waypoint, 'right':right,\n",
    "                                        'oncoming': oncoming, 'left': left}\n",
    "                                stateActionSpace += [self.createStateActionKey(\n",
    "                                    state, action)]\n",
    "        return stateActionSpace\n",
    "    \n",
    "    def createStateActionKey(self, state, action):\n",
    "        return (\"{\"+\n",
    "                (\"'light': {0!r}, 'next_waypoint': {1!r}, 'right': {2!r}, 'oncoming': {3!r},\"\n",
    "                \"'left': {4!r}\").format(state['light'], state['next_waypoint'], state['right'],\n",
    "                                        state['oncoming'], state['left'])+\n",
    "                \"}\" + \n",
    "                \"action: {0!r}\".format(action))\n",
    "    \n",
    "        \n",
    "class LearningAgent(Agent):\n",
    "    \"\"\"An agent that learns to drive in the smartcab world.\"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super(LearningAgent, self).__init__(env)  # sets self.env = env, state = None, \n",
    "                                                  # next_waypoint = None, and a default color\n",
    "        self.color = 'red'  # override color\n",
    "        self.planner = RoutePlanner(self.env, self)  # simple route planner to get next_waypoint\n",
    "        \n",
    "        # TODO: Initialize any additional variables here\n",
    "        self.valid_actions = env.valid_actions\n",
    "        self.valid_inputs = env.valid_inputs\n",
    "        self.utility = Utility(self.valid_actions, self.valid_inputs)\n",
    "    \n",
    "    def reset(self, destination=None):\n",
    "        self.planner.route_to(destination)\n",
    "        # TODO: Prepare for a new trip; reset any variables here, if required\n",
    "\n",
    "    def update(self, t):\n",
    "        # Gather inputs\n",
    "        self.next_waypoint = self.planner.next_waypoint()  # from route planner, also displayed by simulator\n",
    "        inputs = self.env.sense(self)\n",
    "        deadline = self.env.get_deadline(self)\n",
    "        \n",
    "        # TODO: Update state\n",
    "        self.state = {'next_waypoint':str(self.next_waypoint)}\n",
    "        self.state.update(inputs)\n",
    "        old_state = self.state\n",
    "\n",
    "        #Policy(s) = argmax(Q(s,a) , with regard to a)\n",
    "        \n",
    "        action = self.utility.policy(self.state)\n",
    "    \n",
    "        # Execute action and get reward\n",
    "        reward = self.env.act(self, action)\n",
    "        \n",
    "        # TODO: Learn policy based on state, action, reward\n",
    "        self.next_waypoint = self.planner.next_waypoint()  # from route planner, also displayed by simulator\n",
    "        \n",
    "        #get new state\n",
    "        inputs = self.env.sense(self)\n",
    "        self.state = {'next_waypoint':str(self.next_waypoint)}\n",
    "        self.state.update(inputs)\n",
    "        new_state = self.state\n",
    "        \n",
    "        #update utility\n",
    "        self.utility.update(old_state, action, reward, new_state)\n",
    "        \n",
    "        print \"next_waypoint: {}\".format(self.next_waypoint)\n",
    "        print \"LearningAgent.update(): deadline = \" \\\n",
    "        \"{}, inputs = {}, action = {}, reward = {}\".format(deadline, inputs, action, reward)  # [debug]\n",
    "        \n",
    "           \n",
    "\n",
    "def run():\n",
    "    \"\"\"Run the agent for a finite number of trials.\"\"\"\n",
    "\n",
    "    # Set up environment and agent\n",
    "    e = Environment()  # create environment (also adds some dummy traffic)\n",
    "    a = e.create_agent(LearningAgent)  # create agent\n",
    "    e.set_primary_agent(a, enforce_deadline=True)  # specify agent to track\n",
    "    # NOTE: You can set enforce_deadline=False while debugging to allow longer trials\n",
    "\n",
    "    # Now simulate it\n",
    "    sim = Simulator(e, update_delay=0.5, display=False)  # create simulator \n",
    "    # (uses pygame when display=True, if available)\n",
    "    # NOTE: To speed up simulation, reduce update_delay and/or set display=False\n",
    "\n",
    "    sim.run(n_trials=100)  # run for a specified number of trials\n",
    "    # NOTE: To quit midway, press Esc or close pygame window, or hit Ctrl+C on the command-line\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
